{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected 49.60% of all events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:08<00:00, 55.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average track creation time :  18.119633678467043 ms\n",
      "Number of good tracks :  421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load and filter data\n",
    "\n",
    "import sys\n",
    "import time\n",
    "tic = time.time() \n",
    "sys.path.insert(1, 'C:\\\\Users\\\\Pascal\\\\Desktop\\\\TP4a\\\\git\\\\TP4_ECAL-\\\\utils')\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\Pascal\\\\Desktop\\\\TP4a\\\\git_final_final\\\\ecal_reco\\\\tracking')\n",
    "from data_loading import *\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from track_reconstruction import *\n",
    "from hit import Hit\n",
    "from track3D import Track3D\n",
    "from track import Track\n",
    "from parameters import *\n",
    "\n",
    "\n",
    "file_path = 'C:\\\\Users\\\\Pascal\\\\Desktop\\\\TP4a\\\\data\\\\run_000002\\\\data_0000.root' \n",
    "import pandas as pd\n",
    "import uproot\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "N_cons_events = 1000 # number of events to consider\n",
    "\n",
    "br_list_data = ['n_hits', 'tofpet_id', 'tofpet_channel', 'timestamp', 't_coarse', 't_fine', 'timestamp', 'v_coarse', 'v_fine', 'value']\n",
    "br_list_evt = ['timestamp', 'evt_number', 'evt_flags']\n",
    "evt_tree = 'event_data;1'\n",
    "hits_tree = 'event_data;1'\n",
    "\n",
    "with uproot.open(file_path) as tree:\n",
    "    hits_dict = tree[hits_tree].arrays(br_list_data, library=\"np\")\n",
    "    evts_dict = tree[evt_tree].arrays(br_list_evt, library=\"np\")\n",
    "    \n",
    "df_evts = pd.DataFrame.from_dict(evts_dict)\n",
    "df_hits = pd.DataFrame.from_dict(hits_dict)\n",
    "df_hits['timestamp_event'] = df_evts['timestamp']\n",
    "df_hits = df_hits[0:N_cons_events]\n",
    "\n",
    "og_len = len(df_hits)\n",
    "df_hits.query('n_hits > 6', inplace=True)\n",
    "df_hits.query('n_hits < 50', inplace=True)\n",
    "new_len = len(df_hits)\n",
    "print('selected {:.2f}% of all events'.format(new_len/og_len * 100))\n",
    "\n",
    "# create tracks\n",
    "def create_tracks(df, plot = False):\n",
    "    tracks = []\n",
    "    nb_events = len(df['n_hits'])\n",
    "    steps = 9\n",
    "    buff_start = None\n",
    "    buff_evt_idx = None\n",
    "    dts = []\n",
    "    for index, row in tqdm(df.iterrows(), total = df.shape[0]):\n",
    "        channels = row['tofpet_channel']\n",
    "        tofpet_id = row['tofpet_id']\n",
    "        hits = [Hit(row,i) for i in range(row['n_hits'])]\n",
    "        hitsX = [h for h in hits if h.is_sidex]\n",
    "        hitsY = [h for h in hits if not h.is_sidex]\n",
    "        \n",
    "        ## Some events don't have three hits on one of the two sides and are thus not considered\n",
    "        if len(hitsX) > 3 and len(hitsY) > 3:\n",
    "            # get track parameters\n",
    "            track = Track3D(hits)\n",
    "            tracks.append(track)\n",
    "\n",
    "            ## check if track has a \"good\" chi2 value\n",
    "            if track.is_good_2D_fit():\n",
    "            \n",
    "                # worth making a precise track\n",
    "                #track.precise_track()\n",
    "                \n",
    "                ## compute the time of the track\n",
    "                dt = track.get_time_interval()\n",
    "                if dt is not None:\n",
    "                    dts.append(dt)\n",
    "\n",
    "\n",
    "    return tracks, dts\n",
    "    import time\n",
    "t = time.time()\n",
    "trackss, dts = create_tracks(df_hits)\n",
    "print(\"Average track creation time : \", 1000*(time.time()-t)/len(df_hits),\"ms\")\n",
    "good_tracks = [t for t in trackss if t.is_good_2D_fit()]\n",
    "print(\"Number of good tracks : \", len(good_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, r\".\\utils\")\n",
    "sys.path.insert(1, r\".\\tracking\")\n",
    "from hit import Hit\n",
    "from track3D import Track3D\n",
    "from parameters import *\n",
    "from physics import dist_line_rect\n",
    "\n",
    "\n",
    "## This function finds the indices of event which are good candidate for muon decay : good tracks that don't end on a side of the detector\n",
    "## have enough hits on both planes, and close to the reconstructed track, and for which the next event is not too long after and has hits\n",
    "## close to the possible decay point.\n",
    "def find_muon_decay_kim(df, df_total, time_cutoff = 1500, spacial_cutoff = 4000, \\\n",
    "                    save_indices = True, save_hits = True, save_stats = True, save_time_intervals = True,\\\n",
    "                    run_name = \"\", storage_dir = \"\", \\\n",
    "                    return_stats = True):\n",
    "    \"\"\"\n",
    "    Arguments :\n",
    "        -df : data frame filtered containing only the events with a certain range of n_hits\n",
    "        -df_total : data frame containing all events\n",
    "        -time_cutoff : maximal time interval in clock cycles over which a decay is searched\n",
    "        -spacial_cutoff : maximal distance between the end of the muon track and the potential electron in the next event \n",
    "        -save_indices : if True, the indices of the events candidate for muon decay are stored in files with path {storage_dir\"events_indices\"run_name.txt}                     \n",
    "        -save_hits : if True, the lists of hits are stored with pickle in {storage_dir\"pickle_events\"run_name} for each muon decay event\n",
    "        -save_stats : if True, the function saves the filtering stats in a dictionary with pickle in {storage_dir\"filtering_data\"run_name}   \n",
    "        -save_time_intervals : if True, the time intervals are stored in {storage_dir\"time_intervals\"run_name.txt}     \n",
    "        -return_stats : if True, the function returns the number of event filtered out at each step of the algorithm\n",
    "\n",
    "    Returns :\n",
    "        -candidate_index : indices of the events considered by the algorithm as muon decay\n",
    "        -time_intervals : time interval in clock cycle between the muon track and the decay for each decay\n",
    "       The next return numbers are the stats returned if return_stats = True :       \n",
    "        -wrong_number : number of events which contain less that 3 hits in one of the 2 planes\n",
    "        -not_pass_through : number of events for which the last layer in x or y direction contains a hit\n",
    "        -side_touch : number of events for which a hit with the lowest z coordinate is a the side of the detector\n",
    "        -bad_fit : number of events for which the chi square value of the reconstructed track wasn't satisfactory\n",
    "        -last_event_of_df : number of events for which the muon track is the last event of a run : the decay can't be accessed\n",
    "        -hits_far_from_track : number of hits for which all hits at a distance higher than spacial_cutoff of the reconstructed track (preventive part of the code, shouldn't happen)\n",
    "        -too_large_time_interval : number of events for which the next event happend too long after to be considered the product of a decay\n",
    "        -no_spacial_correlation : number of events for which the hits in the next event are far from the end of the track and can thus not be considered\n",
    "                                 as caused by an electron coming from a decay\n",
    "    \"\"\"\n",
    "    candidate_index = []\n",
    "    time_intervals = []\n",
    "    wrong_number = 0\n",
    "    not_pass_through = 0\n",
    "    side_touch = 0\n",
    "    bad_fit = 0\n",
    "    last_event_of_df = 0\n",
    "    too_large_time_interval = 0\n",
    "    no_spacial_correlation = 0\n",
    "    hits_far_from_track = 0\n",
    "    double_hit_same_z=0\n",
    "\n",
    "    if save_hits:\n",
    "        decay_data = {'event_index': [], 'track_x0' : [], 'track_tx' : [], 'track_y0' : [], 'track_ty' : [], 'hits_muon': [], 'hits_electron': [], 'time_interval' : []}\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total = df.shape[0]):  #interated over df, showing a progress bar \n",
    "        hits = [Hit(row,i) for i in range(row['n_hits'])]   #hits is a list corresponding to a row of the DF, it contains contains n_hit element, each one being a Hit\n",
    "        hitsX = [h for h in hits if h.is_sidex]    #filters hits to keep only the Hit where is_sidex is True --> hits on the x side\n",
    "        hitsY = [h for h in hits if not h.is_sidex]\n",
    "        \n",
    "        ## Some events don't have three hits on one of the two sides and are thus not considered\n",
    "        if len(hitsX) == 8  and len(hitsY) == 8 :   #we want the particle to pass through the detector, and to hit once each layer \n",
    "            # The track must go through the whole detector \n",
    "            hitsX.sort(key = lambda hit: -hit.coord[1])\n",
    "            hitsY.sort(key = lambda hit: -hit.coord[1])\n",
    "\n",
    "            if hitsX[-1].coord[1] <= 2 and hitsY[-1].coord[1] <= 2:    #if the track went through the last x and y layers \n",
    "                hitsX_last = [hit for hit in hitsX if hit.coord[1]==hitsX[-1].coord[1]]   #we take all the hit with the same z component than the last hit\n",
    "                hitsY_last = [hit for hit in hitsY if hit.coord[1]==hitsY[-1].coord[1]]\n",
    "                last_x=True\n",
    "                last_y=True\n",
    "\n",
    "                 \n",
    "                if hitsX[0].coord[1] >= 15 and hitsY[0].coord[1] >= 15:    #if the track went through the first x and y layers \n",
    "                    hitsX_first = [hit for hit in hitsX if hit.coord[1]==hitsX[0].coord[1]]   #we take all the hit with the same z component than the last hit\n",
    "                    hitsY_first = [hit for hit in hitsY if hit.coord[1]==hitsY[0].coord[1]]\n",
    "                    first_x=True\n",
    "                    first_y=True\n",
    "    \n",
    "                    if len(hitsX_last) != 0 or len(hitsY_last) !=0 :    #verify the last layer is only hit once\n",
    "                     last_x = False\n",
    "                     last_y= False\n",
    "                     double_hit_same_z+=1\n",
    "                    \n",
    "                    if len(hitsX_first) != 0 or len(hitsY_first) !=0 :    #verify the first layer is only hit once\n",
    "                     first_x = False\n",
    "                     first_y= False\n",
    "                     double_hit_same_z+=1\n",
    "                    \n",
    "                    \n",
    "                    if True:#last_y and last_x and first_x and first_y: \n",
    "                           track = Track3D(hits)\n",
    "       \n",
    "                           ## check if track has a \"good\" chi2 value\n",
    "                           if track.is_good_2D_fit():\n",
    "                               if index+1 >= len(df_total):\n",
    "                                   last_event_of_df += 1\n",
    "                               else:\n",
    "                                   next_event = df_total.loc[index+1]\n",
    "                               \n",
    "           \n",
    "                                   hits_next_event = [Hit(next_event,i) for i in range(next_event['n_hits'])]\n",
    "                                   hitsX_next_event = [hit for hit in hits_next_event if hit.is_sidex]\n",
    "                                   hitsY_next_event = [hit for hit in hits_next_event if not hit.is_sidex]\n",
    "       \n",
    "                                   hitsX = [hit for hit in hitsX if dist_line_rect(track.x.t, track.x.x0, hit.get_pos(), thickness, width) < spacial_cutoff] #Keep only the hits close to the track\n",
    "                                   hitsY = [hit for hit in hitsY if dist_line_rect(track.y.t, track.y.x0, hit.get_pos(), thickness, width) < spacial_cutoff]\n",
    "       \n",
    "                                   ## check if there's still hits in the list after removing the ones far from the reconstructed track\n",
    "                                   if len(hitsX) != 0 or len(hitsY) != 0:\n",
    "       \n",
    "                                       hits_far_from_track +=1\n",
    "       \n",
    "                                   else:\n",
    "                                        candidate_index.append(index)\n",
    "                                        if save_hits:\n",
    "                                            decay_data['event_index'].append(index)\n",
    "                                            decay_data['track_x0'].append(track.x.x0)\n",
    "                                            decay_data['track_tx'].append(track.x.t)\n",
    "                                            decay_data['track_y0'].append(track.y.x0)\n",
    "                                            decay_data['track_ty'].append(track.y.t)\n",
    "                                            decay_data['hits_muon'].append(hits)\n",
    "                                            decay_data['hits_electron'].append(hits_next_event)\n",
    "\n",
    "                           else:\n",
    "                               bad_fit += 1\n",
    "                    else : \n",
    "                      double_hit_same_z=0\n",
    "            else:\n",
    "                not_pass_through += 1\n",
    "        else:\n",
    "            wrong_number += 1\n",
    "\n",
    "\n",
    "    if save_indices:\n",
    "        np.savetxt(storage_dir+\"events_indices\"+run_name+\".txt\", candidate_index)\n",
    "    if save_time_intervals:\n",
    "        np.savetxt(storage_dir+\"time_intervals\"+run_name+\".txt\", time_intervals)\n",
    "    if save_hits:\n",
    "        decay_data = pd.DataFrame.from_dict(decay_data) # translate the dictionary into a pandas dataframe\n",
    "        decay_data.to_pickle(storage_dir+\"pickle_decay_data\"+run_name)\n",
    "    og_len = len(df_total)\n",
    "    new_len = len(df)\n",
    "    filtering = pd.DataFrame({'og_len' : [og_len],\n",
    "                    'new_len' : [new_len],\n",
    "                    'wrong_number' : [wrong_number],\n",
    "                    'not_pass_through' : [not_pass_through],\n",
    "                    'side_touch' : [side_touch],\n",
    "                    'bad_fit': [bad_fit],\n",
    "                    'last_event_of_df' : [last_event_of_df],\n",
    "                    'too_large_time_interval' : [too_large_time_interval],\n",
    "                    'hits_far_from_track' : [hits_far_from_track],\n",
    "                    'no_spacial_correlation' : [no_spacial_correlation]})\n",
    "    if save_stats:\n",
    "        filtering.to_pickle(storage_dir+\"filtering_data\"+run_name)\n",
    "    if return_stats:  \n",
    "        return candidate_index, filtering\n",
    "    else:\n",
    "        return candidate_index, time_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/496 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:01<00:00, 454.81it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       "    og_len  new_len  wrong_number  not_pass_through  side_touch  bad_fit  \\\n",
       " 0     496      496           396                 0           0        0   \n",
       " \n",
       "    last_event_of_df  too_large_time_interval  hits_far_from_track  \\\n",
       " 0                 0                        0                    0   \n",
       " \n",
       "    no_spacial_correlation  \n",
       " 0                       0  )"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_muon_decay_kim(df_hits, df_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/496 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 496/496 [00:02<00:00, 223.52it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Pascal\\Desktop\\TP4a\\git_final_final\\ecal_reco\\time_alignement\\debug.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Pascal/Desktop/TP4a/git_final_final/ecal_reco/time_alignement/debug.ipynb#W3sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m     np\u001b[39m.\u001b[39msavetxt(storage_dir\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtime_intervals\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrun_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m, time_intervals)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Pascal/Desktop/TP4a/git_final_final/ecal_reco/time_alignement/debug.ipynb#W3sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39mif\u001b[39;00m save_hits:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Pascal/Desktop/TP4a/git_final_final/ecal_reco/time_alignement/debug.ipynb#W3sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m     decay_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame\u001b[39m.\u001b[39;49mfrom_dict(decay_data) \u001b[39m# translate the dictionary into a pandas dataframe\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Pascal/Desktop/TP4a/git_final_final/ecal_reco/time_alignement/debug.ipynb#W3sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m     decay_data\u001b[39m.\u001b[39mto_pickle(storage_dir\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpickle_decay_data\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrun_name)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Pascal/Desktop/TP4a/git_final_final/ecal_reco/time_alignement/debug.ipynb#W3sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m og_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(df_total)\n",
      "File \u001b[1;32mc:\\Users\\Pascal\\mambaforge\\envs\\ecal.env\\Lib\\site-packages\\pandas\\core\\frame.py:1816\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[1;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[0;32m   1810\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1811\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m'\u001b[39m\u001b[39m for orient parameter. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1812\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00morient\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1813\u001b[0m     )\n\u001b[0;32m   1815\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 1816\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(data, index\u001b[39m=\u001b[39;49mindex, columns\u001b[39m=\u001b[39;49mcolumns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1817\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1818\u001b[0m     realdata \u001b[39m=\u001b[39m data[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Pascal\\mambaforge\\envs\\ecal.env\\Lib\\site-packages\\pandas\\core\\frame.py:736\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    730\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    731\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    732\u001b[0m     )\n\u001b[0;32m    734\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    735\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    737\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    738\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\Pascal\\mambaforge\\envs\\ecal.env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\Pascal\\mambaforge\\envs\\ecal.env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\Pascal\\mambaforge\\envs\\ecal.env\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    676\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 677\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    679\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    680\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    681\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    682\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(1, r\".\\utils\")\n",
    "sys.path.insert(1, r\".\\tracking\")\n",
    "from hit import Hit\n",
    "from track3D import Track3D\n",
    "from parameters import *\n",
    "\n",
    "from physics import dist_line_rect\n",
    "\n",
    "df = df_hits\n",
    "df_total= df_hits\n",
    "time_cutoff = 1500\n",
    "spacial_cutoff = 4000\n",
    "save_indices = True\n",
    "save_hits = True\n",
    "save_stats= True\n",
    "save_time_intervals = True\n",
    "run_name=\"\"\n",
    "storage_dir = \"\"\n",
    "return_stats = True\n",
    "\n",
    "candidate_index = []\n",
    "time_intervals = []\n",
    "wrong_number = 0\n",
    "not_pass_through = 0\n",
    "side_touch = 0\n",
    "bad_fit = 0\n",
    "last_event_of_df = 0\n",
    "too_large_time_interval = 0\n",
    "no_spacial_correlation = 0\n",
    "hits_far_from_track = 0\n",
    "double_hit_same_z=0\n",
    "DEBUG = 0\n",
    "DEBUG2 = 0\n",
    "if save_hits:\n",
    "    decay_data = {'event_index': [], 'track_x0' : [], 'track_tx' : [], 'track_y0' : [], 'track_ty' : [], 'hits_muon': [], 'hits_electron': [], 'time_interval' : []}\n",
    "\n",
    "for index, row in tqdm(df.iterrows(), total = df.shape[0]):  #interated over df, showing a progress bar \n",
    "    hits = [Hit(row,i) for i in range(row['n_hits'])]   #hits is a list corresponding to a row of the DF, it contains contains n_hit element, each one being a Hit\n",
    "    hitsX = [h for h in hits if h.is_sidex]    #filters hits to keep only the Hit where is_sidex is True --> hits on the x side\n",
    "    hitsY = [h for h in hits if not h.is_sidex]\n",
    "        \n",
    "        ## Some events don't have three hits on one of the two sides and are thus not considered\n",
    "    if len(hitsX) == 8  and len(hitsY) == 8 :   #we want the particle to pass through the detector, and to hit once each layer \n",
    "            # The track must go through the whole detector \n",
    "        hitsX.sort(key = lambda hit: -hit.coord[1])\n",
    "        hitsY.sort(key = lambda hit: -hit.coord[1])\n",
    "        if hitsX[-1].coord[1] <= 1 and hitsY[-1].coord[1] <= 1:    #if the track went through the last x and y layers \n",
    "            hitsX_last = [hit for hit in hitsX if hit.coord[1]==hitsX[-1].coord[1]]   #we take all the hit with the same z component than the last hit\n",
    "            hitsY_last = [hit for hit in hitsY if hit.coord[1]==hitsY[-1].coord[1]]\n",
    "            last_x=True\n",
    "            last_y=True\n",
    "                     \n",
    "                 \n",
    "            if hitsX[0].coord[1] >= 8 and hitsY[0].coord[1] >= 8:    #if the track went through the first x and y layers \n",
    "                hitsX_first = [hit for hit in hitsX if hit.coord[1]==hitsX[0].coord[1]]   #we take all the hit with the same z component than the last hit\n",
    "                hitsY_first = [hit for hit in hitsY if hit.coord[1]==hitsY[0].coord[1]]\n",
    "                first_x=True\n",
    "                first_y=True\n",
    "                if len(hitsX_last) != 1 or len(hitsY_last) != 1 :    #verify the last layer is only hit once\n",
    "                 last_x = False\n",
    "                 last_y= False\n",
    "                 double_hit_same_z+=1\n",
    "                    \n",
    "                if len(hitsX_first) != 1 or len(hitsY_first) != 1 :    #verify the first layer is only hit once\n",
    "                 first_x = False\n",
    "                 first_y= False\n",
    "                 double_hit_same_z+=1\n",
    "                    \n",
    "                    \n",
    "                if last_y and last_x and first_x and first_y: \n",
    "                       track = Track3D(hits)\n",
    "                           ## check if track has a \"good\" chi2 value\n",
    "                       if track.is_good_2D_fit(): \n",
    "                           if index+1 >= len(df_total):\n",
    "                               last_event_of_df += 1\n",
    "                           else:\n",
    "                               next_event = df_total.loc[index]\n",
    "                               \n",
    "           \n",
    "                               hits_next_event = [Hit(next_event,i) for i in range(next_event['n_hits'])]\n",
    "                               hitsX_next_event = [hit for hit in hits_next_event if hit.is_sidex]\n",
    "                               hitsY_next_event = [hit for hit in hits_next_event if not hit.is_sidex]\n",
    "     \n",
    "                               hitsX = [hit for hit in hitsX if dist_line_rect(track.x.t, track.x.x0, hit.get_pos(), thickness, width) < spacial_cutoff] #Keep only the hits close to the track\n",
    "                               hitsY = [hit for hit in hitsY if dist_line_rect(track.y.t, track.y.x0, hit.get_pos(), thickness, width) < spacial_cutoff]\n",
    "                               DEBUG+=1\n",
    "                                   ## check if there's still hits in the list after removing the ones far from the reconstructed track\n",
    "                               if len(hitsX) == 0 or len(hitsY) == 0:\n",
    "                                   DEBUG2+=1\n",
    "                                   hits_far_from_track +=1\n",
    "                               else:\n",
    "                                    candidate_index.append(index)\n",
    "                                    if save_hits:\n",
    "                                        decay_data['event_index'].append(index)\n",
    "                                        decay_data['track_x0'].append(track.x.x0)\n",
    "                                        decay_data['track_tx'].append(track.x.t)\n",
    "                                        decay_data['track_y0'].append(track.y.x0)\n",
    "                                        decay_data['track_ty'].append(track.y.t)\n",
    "                                        decay_data['hits_muon'].append(hits)\n",
    "                                        decay_data['hits_electron'].append(hits_next_event)\n",
    "\n",
    "                       else:\n",
    "                           bad_fit += 1\n",
    "                else : \n",
    "                      double_hit_same_z=0\n",
    "        else:\n",
    "            not_pass_through += 1\n",
    "    else:\n",
    "        wrong_number += 1\n",
    "\n",
    "\n",
    "if save_indices:\n",
    "    np.savetxt(storage_dir+\"events_indices\"+run_name+\".txt\", candidate_index)\n",
    "if save_time_intervals:\n",
    "    np.savetxt(storage_dir+\"time_intervals\"+run_name+\".txt\", time_intervals)\n",
    "if save_hits:\n",
    "    decay_data = pd.DataFrame.from_dict(decay_data) # translate the dictionary into a pandas dataframe\n",
    "    decay_data.to_pickle(storage_dir+\"pickle_decay_data\"+run_name)\n",
    "og_len = len(df_total)\n",
    "new_len = len(df)\n",
    "filtering = pd.DataFrame({'og_len' : [og_len],\n",
    "                'new_len' : [new_len],\n",
    "                'wrong_number' : [wrong_number],\n",
    "                'not_pass_through' : [not_pass_through],\n",
    "                'side_touch' : [side_touch],\n",
    "                'bad_fit': [bad_fit],\n",
    "                'last_event_of_df' : [last_event_of_df],\n",
    "                'too_large_time_interval' : [too_large_time_interval],\n",
    "                'hits_far_from_track' : [hits_far_from_track],\n",
    "                'no_spacial_correlation' : [no_spacial_correlation]})\n",
    "if save_stats:\n",
    "    filtering.to_pickle(storage_dir+\"filtering_data\"+run_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecal.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
